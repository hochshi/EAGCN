{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib; matplotlib.use('agg')\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from utils import *\n",
    "from models import *\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle, resample\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from rdkit import DataStructs\n",
    "\n",
    "random_state = 11\n",
    "nBits = [64, 128, 256, 512, 1024]\n",
    "batch_size = 100\n",
    "num_epochs = 80\n",
    "weight_decay = 0.0001  # L-2 Norm\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels):\n",
    "    X, x_test, y, y_test = train_test_split(data, labels, test_size=0.1, random_state=random_state, stratify=labels)\n",
    "    \n",
    "#     tensor_x_test = torch.from_numpy(x_test).float()\n",
    "#     tensor_y_test = torch.from_numpy(y_test).long()\n",
    "#     test_dataset = torch.utils.data.TensorDataset(tensor_x_test, tensor_y_test)\n",
    "#     test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=random_state, stratify=y)\n",
    "    \n",
    "#     tensor_x_val = torch.from_numpy(x_val).float()\n",
    "#     tensor_y_val = torch.from_numpy(y_val).long()\n",
    "#     val_dataset = torch.utils.data.TensorDataset(tensor_x_val, tensor_y_val)\n",
    "#     val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "    \n",
    "#     tensor_x_train = torch.from_numpy(x_train).float()\n",
    "#     tensor_y_train = torch.from_numpy(y_train).long()\n",
    "#     train_dataset = torch.utils.data.TensorDataset(tensor_x_train, tensor_y_train)\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
    "    \n",
    "#     return (train_loader, val_loader, test_loader)\n",
    "    return ((x_train, y_train), (x_val, y_val), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dist_mat, train_size, train_labels, true_labels):\n",
    "# We assume that the dist matrix is 4 sub matrices, train vs. train train vs. something else.\n",
    "# So the first train_size X train_size entries are the similarity of the train vs. itself.\n",
    "    \n",
    "#     sub_mat = dist_mat[train_size:, :train_size]\n",
    "    sub_mat = dist_mat\n",
    "    correct = [0]*4\n",
    "#     total = dist_mat.shape[0] - train_size\n",
    "    total = dist_mat.shape[0]\n",
    "    top_ks = [1, 5, 10, 30]\n",
    "#     top_ks = np.array(top_ks) - 1\n",
    "    for i, topk in enumerate(top_ks):\n",
    "        nn = np.partition(sub_mat, topk, axis=1)\n",
    "        nn = sub_mat < nn[:,topk].reshape(-1, 1)\n",
    "        nn_labels = np.matmul(nn, train_labels)\n",
    "        correct[i] = (np.multiply(nn_labels, true_labels) > 0).sum()\n",
    "    return np.true_divide(correct,total).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading small_batch_test dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "x_all, y_all, target, sizes, mol_to_graph_transform, parameter_holder, edge_vocab, node_vocab = \\\n",
    "    load_data('small_batch_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [mol_dat[-1] for mol_dat in x_all]\n",
    "uniques, indices = np.unique(mols, return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28792 28869 28792\n"
     ]
    }
   ],
   "source": [
    "print(len(uniques), len(mols), len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "[0.6714120815698346, 0.8410927279722971, 0.8518661023470565, 0.8726433243555214]\n",
      "[0.6692067890543817, 0.8330446830620021, 0.8514028403186699, 0.8708001385521302]\n",
      "128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-25f546b6c1a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnbits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnBits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mAllChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetMorganFingerprintAsBitVect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMolFromInchi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnBits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmol_dat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_all\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlen_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sh/anaconda2/lib/python2.7/site-packages/rdkit/Chem/inchi.pyc\u001b[0m in \u001b[0;36mMolFromInchi\u001b[0;34m(inchi, sanitize, removeHs, logLevel, treatWarningAsError)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdinchi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInchiToMol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minchi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoveHs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for nbits in nBits:\n",
    "    print(nbits)\n",
    "    fps = [AllChem.GetMorganFingerprintAsBitVect(MolFromInchi(mol_dat[-1]), 2, nBits=nbits) for mol_dat in x_all]\n",
    "    len_train = len(fps)\n",
    "    labels = y_all\n",
    "\n",
    "    np_fps = []\n",
    "    for fp in fps:\n",
    "      arr = np.zeros((1,), dtype=np.int8)\n",
    "      DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "      np_fps.append(arr)\n",
    "\n",
    "    np_fps = np.concatenate(np_fps, axis=0)\n",
    "    np_fps = np_fps.reshape(-1, nbits)\n",
    "\n",
    "    np_fps, labels = shuffle(np_fps, labels, random_state=random_state)\n",
    "    train_loader, validation_loader, test_loader = split_data(np_fps, labels)\n",
    "    train_val = cdist(validation_loader[0], train_loader[0], metric='jaccard')\n",
    "    print(test_model(train_val, train_loader[0].shape[0], train_loader[1], validation_loader[1]))\n",
    "    del train_val\n",
    "#     train_val = np.concatenate((train_loader[0], validation_loader[0]))\n",
    "#     train_val = squareform(pdist(train_val, 'jaccard'))\n",
    "\n",
    "#     train_test = np.concatenate((train_loader[0], test_loader[0]))\n",
    "#     train_test = squareform(pdist(train_test, 'jaccard'))\n",
    "    train_test = cdist(test_loader[0], train_loader[0], metric='jaccard')\n",
    "    print(test_model(train_test, train_loader[0].shape[0], train_loader[1], test_loader[1]))\n",
    "    del train_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
